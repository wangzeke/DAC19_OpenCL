\section{Background}

\vspace{-1ex}
\subsection{Traditional OpenCL Programming Model}
Intel provides the OpenCL SDK to abstract the hardware complexities from the traditional FPGA design.
Different from viewing FPGAs as pure hardware resources like LUTs, DSP blocks and memory blocks, the OpenCL SDK regards the FPGA as a large-scale parallel architecture. Typically, OpenCL conceptually divides a problem into equally loaded partitions, in terms of \emph{work-item} which represents the basic unit of execution. A set of work-items are organized into a \emph{work-group} and multiple work-groups are combined to form a three-dimensional index space called \emph{NDRange}. \emph{NDRange kernel} is the default OpenCL kernel model which achieves the pipelined parallelism on FPGAs. 
We introduce two main optimization methods, which are widely adopted by normal and go-beyond OpenCL kernels. We refer the reader to the related work~\cite{fpga_opencl_model_hpca16, opencl_hpc_sc16} for more optimization methods on FPGAs. 

{\bf Multiple Compute Units (CUs). } Suppose the FPGA has sufficient hardware resource, the kernel pipeline can be replicated to generate multiple CUs to achieve more computing parallelism. 

{\bf Loop Unrolling (UL). } If the kernel pipeline contains a large number of loop iterations, the loop iterations could potentially be the critical path due to its unbalance. Unrolling the loop can increase the pipeline throughput at the expense of more hardware resources consumption only for the loop. %And it may have a side-product benefit on FPGAs. The load/store operations can coalesce so that the number of global memory accesses is reduced.


\vspace{-1ex}
\subsection{Go-beyond OpenCL Features on FPGAs}

{\bf Single Work-Item (SWI) Kernel. } 
In addition to the standard NDRange kernel model, Intel OpenCL SDK also supports a SWI kernel, which follows a sequential model like C programming, thus executes the kernel in only one CU that contains only one work-item. In the SWI kernel, the parallelism is implicit, and the OpenCL SDK will instead determine pipelined parallelism at the compilation time based on the dependency. The SWI kernel more closely matches the traditional deep-pipelined nature of FPGAs.


{\bf OpenCL Channel. }
Intel OpenCL SDK provides the \emph{OpenCL channel} feature, which can be used to pass data between two OpenCL kernels (typically SWI) and synchronize the kernels with high efficiency and low latency. The channel allows the kernels to communicate directly with each other via on-chip FIFO buffers. % In the conventional OpenCL implementation, the communication between two kernels is performed via global memory. However, global memory bandwidth could potentially be a performance bottleneck for the kernels. In contrast,

%\vspace{-1ex}
%\subsection{Related Work}
%Hello related work. 
%The OpenCL channel has two types: blocking channel and nonblocking channel. The write/read operation to blocking channel will not return if the operation does not successfully commit, while the write/read operation to nonblocking channel will return even when the operation does not successfully commit.
%The second paragraph has not been modified.





%@Jiantong, you can fill this section, following my paper's style. 


%\subsubsection{OpenCL Concepts} 
%work item, work group, et at. 
%OpenCL is an open parallel programming language for heterogeneous computing environments. It aims for a host-accelerator model of program execution, where a host processor runs control-intensive task and offloads computation-intensive code (i.e., \emph{kernel}) onto an external accelerator.
%The Intel's SDK can translate the high-level OpenCL description to low-level hardware implementation by creating the circuits for each operation of the kernel and interconnect them together to achieve the whole data path.

%From the perspective of OpenCL, the FPGA memory hierarchy contains three layers. First, the \emph{global memory} with high latency and low bandwidth which often refers to the DDRs of the FPGA board. Second, the \emph{local memory} utilizes on-chip low-latency and high-bandwidth BRAMs, and it has four banks in general. Third, the \emph{private memory}, storing the variables or small arrays for each work-item, is constructed using completely-parallel registers. Compared to CPU/GPU, the private memory is rather plentiful in FPGA.
%We can configure multiple kernel pipelines, i.e., Compute Units (CUs) for the NDRange kernel. Then each CU executes the OpenCL program in a pipelined fashion. Although NDRange execution pattern is the most common pattern of using accelerators with OpenCL, it is not mandatory. Actually, in many cases, single work-item kernels are employed as a preferred execution pattern in Altera's OpenCL implementation as explained below.
%\subsubsection{Main Optimization Methods}

%Kernel pipeline replication can achieve higher throughput at the expense of increasing hardware resource utilization, which often leads to a lower FPGA operating frequency than that of one CU. It means that two CUs cannot always double the performance. Another issue is that the global memory load/store operations from multiple CUs compete for the global memory bandwidth and the total number of global memory operations remains unchanged.

%{\bf Shared Memory. } Each CU has its own local memory, which is shared by all the work-items assigned to the CU, while all CUs share a global memory. The on-chip local memory is low-latency and high-throughput compared to global memory. Thus, the local memory can be employed to reduce the number of global memory accesses.

